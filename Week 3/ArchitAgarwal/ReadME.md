# Sentiment Detection in Audio
This project focuses on identifying sentiments in audio files, specifically classifying them into six distinct emotions:
sad, angry, disgust, fear, happiness, and neutrality.

## Approach
The project leverages three neural network architectures to analyze and classify audio data:

1. **LSTM (Long Short-Term Memory)**
Accuracy: 17.06%
2. **Transfer Learning**
Accuracy: 39.83%
3. **Fully Connected Neural Networks**
Accuracy: 40.23%

## Exploratory Data Analysis (EDA)
To gain insights into the audio data and its features, EDA techniques were employed:

1. **MFCC (Mel-Frequency Cepstral Coefficients)**
Visualized to understand frequency-related features.
2. **Mel Spectrograms**
Explored to analyze time-frequency representations of audio signals.

### Visualizations
Plots and visualizations provide deeper insights into the parameters influencing the performance of the neural networks.

