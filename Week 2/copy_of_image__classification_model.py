# -*- coding: utf-8 -*-
"""Copy of Image _classification_model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RX47QdK4e9t6NnS6pSuEGKZ-3709JIuG
"""

import tensorflow as tf
from tensorflow.keras import models, layers, optimizers
from tensorflow.keras.regularizers import l2
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from google.colab import drive
drive.mount('/content/drive')
import zipfile
zip_file_path = '/content/drive/MyDrive/animals.zip'
extract_to_path = '/content/animals'
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to_path)
dataset_path='/content/animals'

dataset = tf.keras.utils.image_dataset_from_directory(
    dataset_path,
    labels="inferred",  # Automatically infer labels from subdirectories
    label_mode="categorical",  # Can be "int", "categorical", or None
    image_size=(128, 128),  # Resize all images to this size
    batch_size=32  # Number of images per batch
)

# Check the dataset
for images, labels in dataset.take(1):
    print("Image shape:", images.shape)
    print("Labels shape:", labels.shape)


train_images, train_labels = [], []
test_images, test_labels = [], []

# Assuming the dataset is split into train and test sets, adjust accordingly
for images, labels in dataset:
    # Convert tensors to NumPy arrays
    images = images.numpy()
    labels = labels.numpy()

    # Add data to the respective lists
    # You might need to adjust this based on how your dataset is structured
    # (e.g., if you have a separate test set, handle it accordingly)
    train_images.extend(images)
    train_labels.extend(labels)
    test_images.extend(images)
    test_labels.extend(labels)

# Convert lists to NumPy arrays
train_images = np.array(train_images)/255
train_labels = np.array(train_labels)
test_images = np.array(test_images)/255
test_labels = np.array(test_labels)

class_names = dataset.class_names
print(class_names)

plt.figure
plt.imshow(train_images[5])
plt.colorbar()
plt.grid()
plt.title(class_names[np.argmax(train_labels[5])])

plt.axis("off")
plt.show()

plt.figure(figsize=(10,10))
for i in range(36):
    plt.subplot(6,6,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    #plt.xlabel(class_name[train_labels[i]])
    predicted_label_index = np.argmax(train_labels[i])
    plt.xlabel(class_names[predicted_label_index])
plt.show()

model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.001), input_shape=(128, 128, 3)),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.001)),
    layers.Dropout(0.5),
    layers.Dense(15, activation='softmax')
])

model.compile(optimizer=optimizers.Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=20)

test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

print('\nTest accuracy:', test_acc)

probability_model = tf.keras.Sequential([model,
                                         tf.keras.layers.Softmax()])

predictions = probability_model.predict(test_images)

predictions[5]

print(np.argmax(predictions[0]))
print(np.argmax(predictions[5]))

def plot_image(i, predictions_array, true_label, img):
  true_label, img = true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)
  true_label_index = np.argmax(true_label)
  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label_index:
    color = 'yellow'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label_index]),
                                color=color)

def plot_value_array(i, predictions_array, true_label):
  true_label = true_label[i]
  plt.grid(False)
  plt.xticks(range(len(predictions_array)))
  plt.yticks([])
  thisplot = plt.bar(range(len(predictions_array)), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  true_label_index = np.argmax(true_label)
  thisplot[true_label_index].set_color('blue')
num_rows = 10
num_cols = 5
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions[i], test_labels, test_images)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_value_array(i, predictions[i], test_labels)
plt.tight_layout()
plt.show()

print("Model accuracy is : ",test_acc*100)