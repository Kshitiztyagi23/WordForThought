{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP9SJ1/56+6GJ+I7T3Yf2yl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import zipfile\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from sklearn.metrics import classification_report, confusion_matrix\n","from google.colab import files\n","import matplotlib.pyplot as plt\n","\n","uploaded = files.upload()\n","zip_file_path = list(uploaded.keys())[0]\n","\n","dataset_path = \"./dataset\"\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","    zip_ref.extractall(dataset_path)\n","\n","train_path = os.path.join(dataset_path, 'train')\n","val_path = os.path.join(dataset_path, 'val')\n","test_path = os.path.join(dataset_path, 'test')\n","\n","img_size = (150, 150)\n","batch_size = 32\n","\n","data_gen_args = {\n","    \"rescale\": 1.0 / 255.0,\n","    \"rotation_range\": 20,\n","    \"width_shift_range\": 0.2,\n","    \"height_shift_range\": 0.2,\n","    \"shear_range\": 0.2,\n","    \"zoom_range\": 0.2,\n","    \"horizontal_flip\": True\n","}\n","train_gen = ImageDataGenerator(**data_gen_args).flow_from_directory(\n","    train_path, target_size=img_size, batch_size=batch_size, class_mode='categorical'\n",")\n","val_gen = ImageDataGenerator(rescale=1.0 / 255.0).flow_from_directory(\n","    val_path, target_size=img_size, batch_size=batch_size, class_mode='categorical'\n",")\n","test_gen = ImageDataGenerator(rescale=1.0 / 255.0).flow_from_directory(\n","    test_path, target_size=img_size, batch_size=batch_size, class_mode='categorical', shuffle=False\n",")\n","\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 3)),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(train_gen.num_classes, activation='softmax')\n","])\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","\n","model.fit(train_gen, validation_data=val_gen, epochs=20)\n","\n","eval_loss, eval_acc = model.evaluate(test_gen)\n","print(f\"\\nTest Loss: {eval_loss}\\nTest Accuracy: {eval_acc}\")\n","\n","preds = np.argmax(model.predict(test_gen), axis=1)\n","true_labels = test_gen.classes\n","print(\"\\nClassification Report:\")\n","print(classification_report(true_labels, preds, target_names=list(test_gen.class_indices.keys())))\n","print(\"\\nConfusion Matrix:\")\n","print(confusion_matrix(true_labels, preds))\n","\n","model.save(\"image_classification_model.h5\")\n","\n","def predict_single_image(model, img_path, class_indices, img_size=(150, 150)):\n","    img = image.load_img(img_path, target_size=img_size)\n","    img_array = image.img_to_array(img)\n","    img_array = img_array / 255.0\n","    img_array = np.expand_dims(img_array, axis=0)\n","\n","    predictions = model.predict(img_array)\n","    predicted_class = np.argmax(predictions, axis=1)[0]\n","\n","    class_labels = {v: k for k, v in class_indices.items()}\n","    predicted_label = class_labels[predicted_class]\n","\n","    plt.imshow(img)\n","    plt.axis('off')\n","    plt.title(f\"Prediction: {predicted_label}\")\n","    plt.show()\n","\n","    return predicted_label\n","\n","test_image_path = input(\"Enter the path of an image to test: \")\n","predicted_label = predict_single_image(model, test_image_path, test_gen.class_indices)\n","print(f\"Predicted Label: {predicted_label}\")\n"],"metadata":{"id":"HGkpwduCZ1fO"},"execution_count":null,"outputs":[]}]}