{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNyMN8TiWjlgxoeTGZ2FCVP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lEohpMBe87Gl"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers, models\n","import matplotlib.pyplot as plt\n","\n","# Uploading the zip file\n","from google.colab import drive\n","import zipfile\n","import os\n","from google.colab import files\n","uploaded = files.upload()\n","zip_path = \"animals.zip\"\n","extract = \"animals_data\"\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract)\n","data = os.path.join(extract, 'animal_data')\n","\n","# Processing the data\n","train_data = ImageDataGenerator(\n","    rescale=1.0/255.0,\n","    validation_split=0.2,\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","train = train_data.flow_from_directory(\n","    data,\n","    target_size=(150, 150),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='training'\n",")\n","\n","validation = train_data.flow_from_directory(\n","    data,\n","    target_size=(150, 150),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='validation'\n",")\n","\n","# Building the model\n","model = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(train_generator.num_classes, activation='softmax')\n","])\n","\n","# Compiling\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Training\n","history = model.fit(\n","    train,\n","    epochs=10,\n","    validation_data=validation,\n","    steps_per_epoch=train.samples // train.batch_size,\n","    validation_steps=validation.samples // validation.batch_size\n",")\n","\n","# Plotting Training and Validation Metrics\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(len(acc))\n","plt.figure(figsize=(12, 6))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs, acc, 'r', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs, loss, 'r', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()\n","\n","# Step 7: Evaluating\n","test_loss, test_acc = model.evaluate(validation)\n","print(\"\\nAccuracy:\", test_acc)"]}]}